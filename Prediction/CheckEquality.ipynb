{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CheckEquality.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","   \n","from numpy import argmax\n","import keras\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from datetime import datetime\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","InputFile ='/content/drive/MyDrive//Dataset/CheckEquality.xlsx'\n","Model_Path ='/content/drive/MyDrive/Dataset/28_4_LastModel'\n","OutputFile ='/content/drive/MyDrive/Dataset/Predicted_Trend'+datetime.now().strftime(\"%d_%m_%Y_%H_%M\")+'.xlsx'\n","\n","def find_MaxtimeStep(df):\n","    # x = df.loc[df['INDEX'].notnull()].index.tolist()\n","    # max_distance =0 \n","    # for i in range (0,len(x)-1):\n","    #     if x[i+1]-x[i] >max_distance:\n","    #         max_distance = x[i+1]-x[i]\n","    return 700\n","def get_fixedSizeCandle(candles,md):\n","    candles_array = np.array(candles)\n","    Fixed_MaxSizeCandles = np.zeros((md,candles_array.shape[1]),dtype=float)\n","    Fixed_MaxSizeCandles[md-candles_array.shape[0]:,:candles_array.shape[1]] =candles_array\n","    return Fixed_MaxSizeCandles\n","\n","def PrepareTestData(df,Max_TimeStep):   \n","    x=list()\n","    y=list()\n","    i=0\n","    candles = list()\n","    while i<len(df):\n","        candle =list()\n","        candle = np.zeros(4)\n","        if not(pd.isnull(df.at[i,'INDEX'])):\n","            y.append(df.at[i,'INDEX'])\n","            if len(candles)>0:\n","                    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","            candles = list()\n","        else:\n","            for j in range (0,4):\n","                candle[j] = df.iloc[i,j+2] -df.iloc[i-1,j+2]\n","                #candle[j] = df.iloc[i,j+2]\n","        candles.append(candle)\n","        i = i+1\n","    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","    return np.array(x),np.array(y)\n","\n","excel_test_data =  pd.read_excel(InputFile)\n","df1 = pd.DataFrame(excel_test_data, columns=['DATE', 'TIME', 'OPEN','HIGH','LOW','CLOSE','TREND','INDEX'])\n","Max_TimeStep = find_MaxtimeStep(df1)\n","testX,textY = PrepareTestData(df1,Max_TimeStep)\n","scaler = StandardScaler()\n","pd.DataFrame(testX[0]).to_excel('/content/drive/MyDrive//Dataset/TestEquality_BeforeNormalize.xlsx')\n","for i in range(0,testX.shape[0]):\n","   testX[i]= scaler.fit_transform(testX[i])\n","pd.DataFrame(testX[0]).to_excel('/content/drive/MyDrive//Dataset/TestEquality_Afternormalize.xlsx')\n","model = keras.models.load_model(Model_Path)\n","testPredict = model.predict(testX)\n","df1[['BreakDown','BreakUp','Channel','Down','Side','Up']] = pd.DataFrame(testPredict)\n","\n","trendlist = df1.loc[df1['INDEX'].notnull()].index.tolist()\n","answer = [\"\" for i in range(len(df1))]\n","BreakDown = [\"\" for i in range(len(df1))]\n","BreakUp = [\"\" for i in range(len(df1))]\n","Channel = [\"\" for i in range(len(df1))]\n","Down = [\"\" for i in range(len(df1))]\n","Side = [\"\" for i in range(len(df1))]\n","Up = [\"\" for i in range(len(df1))]\n","key=['BreakDown','BreakUp','Channel','Down','Side','Up']\n","for i in range(0,len(trendlist)):\n","  answer[trendlist[i]] =key[argmax(testPredict[i, :])]\n","  BreakDown[trendlist[i]] =testPredict[i, 0]\n","  BreakUp[trendlist[i]] =testPredict[i, 1]\n","  Channel[trendlist[i]] =testPredict[i, 2]\n","  Down[trendlist[i]] =testPredict[i, 3]\n","  Side[trendlist[i]] =testPredict[i, 4]\n","  Up[trendlist[i]] =testPredict[i, 5]\n","df1['BreakDown'] = BreakDown\n","df1['BreakUp'] = BreakUp\n","df1['Channel'] = Channel\n","df1['PredictedTrend'] = answer\n","df1['Down'] = Down\n","df1['Side'] = Side\n","df1['Up'] = Up\n","df1.to_excel(OutputFile)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAQX1k8r3br2","executionInfo":{"status":"ok","timestamp":1660546973421,"user_tz":-270,"elapsed":15536,"user":{"displayName":"Mahmood(Iman) Soltani","userId":"11163060554270252808"}},"outputId":"eb7f2a1e-8f6a-46f0-cb41-d53369a75cfb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb9be956e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4XsFUb-2fPg2"},"execution_count":null,"outputs":[]}]}