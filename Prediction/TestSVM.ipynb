{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestSVM.ipynb","provenance":[],"authorship_tag":"ABX9TyPG+ym515AVdGvpQ98ZOllT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gK00cboZtxZT","executionInfo":{"status":"ok","timestamp":1659001370174,"user_tz":-270,"elapsed":9880,"user":{"displayName":"Mahmood(Iman) Soltani","userId":"11163060554270252808"}},"outputId":"d23dadd7-1f8c-4efa-f8a5-84b7c99affc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyts in /usr/local/lib/python3.7/dist-packages (0.12.0)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.2)\n","Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.21.6)\n","Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.7.3)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.1.0)\n","Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.51.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (57.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Preparing Data ...\n","Reading data...\n","Reading data Complete!\n","Creating Input Array ...\n","Data is Ready ... (sample size:\n","(8, 337, 4)\n","(8, 4, 337)\n","(8,)\n","(2, 4, 337)\n","['Break DownTrend' 'UpTrend']\n","['Break DownTrend' 'Side']\n"]}],"source":["!pip install pyts\n","from pyts.classification import BOSSVS\n","from pyts.datasets import load_basic_motions\n","from pyts.multivariate.classification import MultivariateClassifier\n","\n","\n","from os import system\n","from sklearn.model_selection import KFold\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","from keras.layers import Bidirectional\n","from keras.layers import Attention\n","import numpy as np\n","import sys\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive\n","drive.mount('/content/drive')\n","np.set_printoptions(threshold=sys.maxsize)\n","# from scipy.signal import argrelextrema\n","# from statsmodels.nonparametric.kernel_regression import KernelReg\n","def find_MaxtimeStep(df):\n","    x = df.loc[df['TREND'].notnull()].index.tolist()\n","    max_distance =0 \n","    for i in range (0,len(x)-1):\n","        if x[i+1]-x[i] >max_distance:\n","            max_distance = x[i+1]-x[i]\n","    return max_distance\n","def get_fixedSizeCandle(candles,md):\n","    candles_array = np.array(candles)\n","    Fixed_MaxSizeCandles = np.zeros((md,candles_array.shape[1]),dtype=float)\n","    Fixed_MaxSizeCandles[md-candles_array.shape[0]:,:candles_array.shape[1]] =candles_array\n","    return Fixed_MaxSizeCandles\n","\n","def PrepareData(path):\n","    print ('Reading data...')\n","    excel_data = pd.read_excel(path)\n","    df = pd.DataFrame(excel_data, columns=['DATE', 'TIME', 'OPEN','HIGH','LOW','CLOSE','TREND'])\n","    print ('Reading data Complete!')\n","    print ('Creating Input Array ...')\n","    \n","    Max_TimeStep = find_MaxtimeStep(df)\n","    x=list()\n","    y=list()\n","    i=0\n","    candles = list()\n","    while i<len(df):\n","        candle =list()\n","        candle = np.zeros(4)\n","        if not(pd.isnull(df.at[i,'TREND'])):\n","            y.append(df.at[i,'TREND'])\n","            if len(candles)>0:\n","                    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","            candles = list()\n","        else:\n","          for j in range (0,4):\n","              candle[j] = df.iloc[i,j+2] -df.iloc[i-1,j+2]\n","            #candle[j] = df.iloc[i,j+2]\n","        candles.append(candle)\n","        i = i+1\n","        \n","    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","    x = np.array(x)\n","    y = np.array(y)\n","    scaler = StandardScaler()\n","    for i in range(0,x.shape[0]):\n","        x[i]= scaler.fit_transform(x[i])\n","    #x = scaler.fit_transform(x.reshape(-1, x.shape[-1])).reshape(x.shape)\n","    label_encoder = LabelEncoder()\n","    # print (y)\n","    # integer_encoded = label_encoder.fit_transform(y)\n","    # print(integer_encoded)\n","    # onehot_encoder = OneHotEncoder(sparse=False)\n","    # integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","    # onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","    # print ('Creating Input Array Complete!')\n","    # return np.array(x),np.array(onehot_encoded),Max_TimeStep\n","    return np.array(x),np.array(y),Max_TimeStep\n","\n","def Create_Model(num_timesteps,num_features):\n","    model = Sequential()\n","    model.add(LSTM(64, return_sequences=True, input_shape=(num_timesteps, num_features)))\n","    model.add(Bidirectional(LSTM(32)))\n","    model.add(Dense(16))\n","    model.add(Dense(6,activation= 'softmax'))\n","    return model\n","\n","def Show_history_plot(history):\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","def Create_Train_Test(x,y,test_Persent):\n"," \n","    X_Train = x[:int((100-test_Persent)*x.shape[0]/100),:,:]\n","    X_Test = x[(X_Train.shape[0]):,:,:]\n","    Y_Train = y[:X_Train.shape[0]]\n","    Y_Test = y[X_Train.shape[0]:]\n","    return X_Train,X_Test,Y_Train,Y_Test\n","\n","#set parameters\n","test_Persent = 15\n","Max_TimeStep=0\n","Max_TimeStep1=0\n","print('Preparing Data ...')\n","x,y,Max_TimeStep = PrepareData('/content/drive/MyDrive/Dataset/SampleTestData.xlsx')\n","#x1,y1, = PreparetestData('/content/drive/MyDrive/Test_Sample.xlsx',Max_TimeStep)\n","X_Train,X_Test,Y_Train,Y_Test = Create_Train_Test(x,y,test_Persent)\n","print('Data is Ready ... (sample size:')\n","print(X_Train.shape)\n","X_Train= X_Train.transpose(0,2,1)\n","X_Test= X_Test.transpose(0,2,1)\n","print(X_Train.shape)\n","print(Y_Train.shape)\n","\n","clf = MultivariateClassifier(BOSSVS(strategy ='normal'))\n","clf.fit(X_Train, Y_Train)\n","MultivariateClassifier(...)\n","clf.score(X_Train, Y_Train)\n","a = clf.predict(X_Test)\n","print(X_Test.shape)\n","print(Y_Test)\n","print (a)"]}]}