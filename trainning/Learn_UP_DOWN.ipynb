{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgjXmUilePLBk5q1I5+f58"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ejJ_udzouAr","executionInfo":{"status":"ok","timestamp":1662318916997,"user_tz":-270,"elapsed":238284,"user":{"displayName":"Mahmood(Iman) Soltani","userId":"11163060554270252808"}},"outputId":"84dc1d0d-9428-4a74-e14c-013019003c6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Preparing Data ...\n","Reading data...\n","Reading data Complete!\n","Creating Input Array ...\n","Creating Input Array Complete!\n","(128, 500, 4)\n","(1152, 500, 4)\n","(128, 2)\n","(1152, 2)\n","Data is Ready ... \n","(1280, 500, 4) 500\n","Epoch 1/2\n","36/36 - 35s - loss: 0.1519 - accuracy: 0.9505 - 35s/epoch - 978ms/step\n","Epoch 2/2\n","36/36 - 31s - loss: 0.0048 - accuracy: 0.9991 - 31s/epoch - 858ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7faaf6fbfbd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fab00272b10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fab00751350> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["[0.00021311394812073559, 1.0]\n"]}],"source":["from os import system\n","from sklearn.model_selection import KFold\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","from keras.layers import Bidirectional\n","from keras.layers import Attention\n","import numpy as np\n","import sys\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from pickle import dump\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","np.set_printoptions(threshold=sys.maxsize)\n","# from scipy.signal import argrelextrema\n","# from statsmodels.nonparametric.kernel_regression import KernelReg\n","def find_MaxtimeStep(df):\n","    x = df.loc[df['TREND'].notnull()].index.tolist()\n","    max_distance =0\n","    for i in range (0,len(x)-1):\n","        if x[i+1]-x[i] >max_distance:\n","            max_distance = x[i+1]-x[i]\n","    return max_distance\n","def get_fixedSizeCandle(candles,md):\n","    candles_array = np.array(candles)\n","    Fixed_MaxSizeCandles = np.zeros((md,candles_array.shape[1]),dtype=float)\n","    Fixed_MaxSizeCandles[md-candles_array.shape[0]:,:candles_array.shape[1]] =candles_array\n","    return Fixed_MaxSizeCandles\n","\n","def PreparetestData(path,Max_TimeStep):\n","    print ('Reading data...')\n","    excel_data = pd.read_excel(path)\n","    df = pd.DataFrame(excel_data, columns=['DATE', 'TIME', 'OPEN','HIGH','LOW','CLOSE','TREND'])\n","    print ('Reading data Complete!')\n","    print ('Creating Input Array ...')\n","\n","    x=list()\n","    y=list()\n","    i=0\n","    candles = list()\n","    while i<len(df):\n","        candle =list()\n","        candle = np.zeros(4)\n","        if not(pd.isnull(df.at[i,'TREND'])):\n","            y.append(df.at[i,'TREND'])\n","            if len(candles)>0:\n","                    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","            candles = list()\n","        else:\n","          for j in range (0,4):\n","              candle[j] = df.iloc[i,j+2] -df.iloc[i-1,j+2]\n","            #candle[j] = df.iloc[i,j+2]\n","        candles.append(candle)\n","        i = i+1\n","    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","    x = np.array(x)\n","    y = np.array(y)\n","    scaler = StandardScaler()\n","    for i in range(0,x.shape[0]):\n","        x[i]= scaler.fit_transform(x[i])\n","    #x = scaler.fit_transform(x.reshape(-1, x.shape[-1])).reshape(x.shape)\n","    label_encoder = LabelEncoder()\n","    integer_encoded = label_encoder.fit_transform(y)\n","    onehot_encoder = OneHotEncoder(sparse=False)\n","    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","    print ('Creating Input Array Complete!')\n","    return np.array(x),np.array(onehot_encoded)\n","\n","def PrepareData(path):\n","    print ('Reading data...')\n","    excel_data = pd.read_excel(path)\n","    df = pd.DataFrame(excel_data, columns=['DATE', 'TIME', 'OPEN','HIGH','LOW','CLOSE','TREND'])\n","    print ('Reading data Complete!')\n","    print ('Creating Input Array ...')\n","\n","    Max_TimeStep = find_MaxtimeStep(df)\n","    x=list()\n","    y=list()\n","    i=0\n","    candles = list()\n","    while i<len(df):\n","        candle =list()\n","        candle = np.zeros(4)\n","        if not(pd.isnull(df.at[i,'TREND'])):\n","            y.append(df.at[i,'TREND'])\n","            if len(candles)>0:\n","                    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","            candles = list()\n","        else:\n","          for j in range (0,4):\n","              candle[j] = df.iloc[i,j+2] -df.iloc[i-1,j+2]\n","            #candle[j] = df.iloc[i,j+2]\n","        candles.append(candle)\n","        i = i+1\n","\n","    x.append(get_fixedSizeCandle(candles,Max_TimeStep))\n","    x = np.array(x)\n","    y = np.array(y)\n","    scaler = StandardScaler()\n","    for i in range(0,x.shape[0]):\n","      x[i]= scaler.fit_transform(x[i])\n","    #x = scaler.fit_transform(x.reshape(-1, x.shape[-1])).reshape(x.shape)\n","    #dump(scaler, open('/content/drive/MyDrive/Dataset/std_scaler.bin', 'wb'))\n","    label_encoder = LabelEncoder()\n","    integer_encoded = label_encoder.fit_transform(y)\n","    onehot_encoder = OneHotEncoder(sparse=False)\n","    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","    print ('Creating Input Array Complete!')\n","    return np.array(x),np.array(onehot_encoded),Max_TimeStep\n","\n","def Create_Model(num_timesteps,num_features):\n","    model = Sequential()\n","    model.add(LSTM(128, return_sequences=True, input_shape=(num_timesteps, num_features)))\n","    model.add(Bidirectional(LSTM(64)))\n","    model.add(Dense(32))\n","    model.add(Dense(2,activation= 'softmax'))\n","    return model\n","\n","def Create_Train_Test(x,y,test_Persent):\n","    X_Test = x[0:int((test_Persent)*x.shape[0]/100),:,:]\n","    X_Train = x[(X_Test.shape[0]):,:,:]\n","    Y_Test= y[0:X_Test.shape[0],:]\n","    Y_Train = y[X_Test.shape[0]:,:]\n","    print(X_Test.shape)\n","    print(X_Train.shape)\n","    print(Y_Test.shape)\n","    print(Y_Train.shape)\n","    return X_Train,X_Test,Y_Train,Y_Test\n","\n","#set parameters\n","test_Persent = 10\n","Max_TimeStep=0\n","Max_TimeStep1=0\n","print('Preparing Data ...')\n","x,y,Max_TimeStep = PrepareData('/content/drive/MyDrive/Dataset/DataSet_Up_Down.xlsx')\n","#x1,y1, = PreparetestData('/content/drive/MyDrive/Test_Sample.xlsx',Max_TimeStep)\n","X_Train,X_Test,Y_Train,Y_Test = Create_Train_Test(x,y,test_Persent)\n","\n","print('Data is Ready ... ')\n","print( x.shape,Max_TimeStep)\n","\n","model = Create_Model(Max_TimeStep,X_Train.shape[2])\n","model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","history= model.fit(X_Train, Y_Train, epochs=2,  verbose=2)\n","model.save('/content/drive/MyDrive/Dataset/8_31_UD_2Epoch_Model')\n","scores =model.evaluate(X_Test,Y_Test,verbose=0)\n","print(scores)\n"]}]}